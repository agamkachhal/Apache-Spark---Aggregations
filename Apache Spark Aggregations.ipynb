{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4568f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the spark session\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "spark = SparkSession. \\\n",
    "builder. \\\n",
    "config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "appName(\"Agam_aggregations\"). \\\n",
    "enableHiveSupport(). \\\n",
    "master(\"yarn\"). \\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b963ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://g02.itversity.com:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Agam_aggregations</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fae875e0e10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87c8ea3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Let's define the schema so we can enforce it later while reading the file rather than infer.\n",
    "    I am using the hotel data for carrying out the analysis in this notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d0146e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+-------------+--------------+---------+-----+\n",
      "|customer_id|customer_name    |check_in_date|check_out_date|room_type|price|\n",
      "+-----------+-----------------+-------------+--------------+---------+-----+\n",
      "|2          |Jane Smith       |2023-05-02   |2023-05-06    |Deluxe   |600.0|\n",
      "|3          |Mark Johnson     |2023-05-03   |2023-05-08    |Standard |450.0|\n",
      "|4          |Sarah Wilson     |2023-05-04   |2023-05-07    |Executive|750.0|\n",
      "|5          |Emily Brown      |2023-05-06   |2023-05-09    |Deluxe   |550.0|\n",
      "|6          |Michael Davis    |2023-05-07   |2023-05-10    |Standard |400.0|\n",
      "|7          |Samantha Thompson|2023-05-08   |2023-05-12    |Deluxe   |600.0|\n",
      "|8          |William Lee      |2023-05-10   |2023-05-13    |Standard |450.0|\n",
      "|9          |Amanda Harris    |2023-05-11   |2023-05-16    |Executive|750.0|\n",
      "|10         |David Rodriguez  |2023-05-12   |2023-05-15    |Deluxe   |550.0|\n",
      "|11         |Linda Wilson     |2023-05-14   |2023-05-18    |Standard |400.0|\n",
      "|12         |Robert Johnson   |2023-05-15   |2023-05-20    |Deluxe   |600.0|\n",
      "|13         |Sophia Anderson  |2023-05-16   |2023-05-21    |Standard |450.0|\n",
      "|14         |James Smith      |2023-05-17   |2023-05-23    |Executive|750.0|\n",
      "|15         |Olivia Brown     |2023-05-19   |2023-05-24    |Deluxe   |550.0|\n",
      "|16         |Michael Davis    |2023-05-20   |2023-05-25    |Standard |400.0|\n",
      "|17         |Emily Thompson   |2023-05-21   |2023-05-27    |Deluxe   |600.0|\n",
      "|18         |William Lee      |2023-05-23   |2023-05-28    |Standard |450.0|\n",
      "|19         |Ava Harris       |2023-05-24   |2023-05-30    |Executive|750.0|\n",
      "|20         |Daniel Rodriguez |2023-05-25   |2023-05-29    |Deluxe   |550.0|\n",
      "|21         |Sophia Wilson    |2023-05-27   |2023-06-01    |Standard |400.0|\n",
      "+-----------+-----------------+-------------+--------------+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hotel_schema = \"customer_id long, customer_name string, check_in_date date, check_out_date date, room_type string, price float\"\n",
    "\n",
    "# Read the data from HDFS location\n",
    "hotel_data = spark.read.format(\"csv\").option(\"header\", \"true\").schema(hotel_schema).load(\"/public/trendytech/datasets/hotel_data.csv\")\n",
    "\n",
    "# Print the first 20 rows to see the data format\n",
    "hotel_data.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f335f9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- customer_name: string (nullable = true)\n",
      " |-- check_in_date: date (nullable = true)\n",
      " |-- check_out_date: date (nullable = true)\n",
      " |-- room_type: string (nullable = true)\n",
      " |-- price: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the dataframe schema to ensure all columns are of correct data types as intended\n",
    "\n",
    "hotel_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59414379",
   "metadata": {},
   "source": [
    "**Now let's deep dive to perform some simple and Grouping aggregations first:**\n",
    "\n",
    "`Note: I will follow the Spark SQL style in this notebook to perform different aggregations. We will cover the below scenarios as part of simple aggregations:`\n",
    "\n",
    "* Get total records from the dataframe\n",
    "* Get all distinct room types.\n",
    "* Calculate total price for each room type\n",
    "* Calculate avg. price for each room type\n",
    "* Find out customers who have stayed more than or equal to 10 times in different types of rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51ef60e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the sql funcations from Pyspark3 to run the code\n",
    "\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95afa2e",
   "metadata": {},
   "source": [
    "##### `Creating a spark table from the dataframe which can be then used to perform different actions.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c1d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_data.createOrReplaceTempView(\"hoteldata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a136f5a1",
   "metadata": {},
   "source": [
    "_`Let's use the basic count() aggregate first to see how many records we have in our dataframe:`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f49ca80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>total_rows</th></tr>\n",
       "<tr><td>106</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+\n",
       "|total_rows|\n",
       "+----------+\n",
       "|       106|\n",
       "+----------+"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select count(*) as total_rows from hoteldata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d968207",
   "metadata": {},
   "source": [
    "_`Let's now see how many number of customers are there for distinct room types in this dataset:`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c813fd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>room_type</th><th>number_of_customers</th></tr>\n",
       "<tr><td>Executive</td><td>20</td></tr>\n",
       "<tr><td>Deluxe</td><td>43</td></tr>\n",
       "<tr><td>Standard</td><td>43</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+-------------------+\n",
       "|room_type|number_of_customers|\n",
       "+---------+-------------------+\n",
       "|Executive|                 20|\n",
       "|   Deluxe|                 43|\n",
       "| Standard|                 43|\n",
       "+---------+-------------------+"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select room_type, count(customer_id) as number_of_customers from hoteldata group by room_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30644bae",
   "metadata": {},
   "source": [
    "_`Let's find out the total price for different categories of rooms listed:`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf043867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>total_price</th><th>room_type</th></tr>\n",
       "<tr><td>24750.0</td><td>Deluxe</td></tr>\n",
       "<tr><td>18300.0</td><td>Standard</td></tr>\n",
       "<tr><td>15000.0</td><td>Executive</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+---------+\n",
       "|total_price|room_type|\n",
       "+-----------+---------+\n",
       "|    24750.0|   Deluxe|\n",
       "|    18300.0| Standard|\n",
       "|    15000.0|Executive|\n",
       "+-----------+---------+"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select sum(price) as total_price, room_type from hoteldata group by room_type order by total_price DESC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ff5c94",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>We get to know that most people prefer Deluxe rooms so the total price is highest for these rooms over all the entries\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3b0a68",
   "metadata": {},
   "source": [
    "_`Let's find out the average price for different categories of rooms listed:`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "158903b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>average_price</th><th>room_type</th></tr>\n",
       "<tr><td>750.0</td><td>Executive</td></tr>\n",
       "<tr><td>575.58</td><td>Deluxe</td></tr>\n",
       "<tr><td>425.58</td><td>Standard</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------+---------+\n",
       "|average_price|room_type|\n",
       "+-------------+---------+\n",
       "|        750.0|Executive|\n",
       "|       575.58|   Deluxe|\n",
       "|       425.58| Standard|\n",
       "+-------------+---------+"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select round(avg(price),2) as average_price, room_type from hoteldata group by room_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac91228",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Even when most people prefer Deluxe rooms for their stay, we see Average price for Executive rooms to be highest and that is because all the price entries for Executive rooms have 750 conistently, however Deluxe rooms are offered on different rates across different dates. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91f15fb",
   "metadata": {},
   "source": [
    "_`Let's find out top customers who have stayed more than or equal to 10 times in different types of rooms listed:`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a970f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>customer_name</th><th>room_type</th><th>total_entries</th></tr>\n",
       "<tr><td>James Smith</td><td>Executive</td><td>10</td></tr>\n",
       "<tr><td>Robert Johnson</td><td>Deluxe</td><td>10</td></tr>\n",
       "<tr><td>William Lee</td><td>Standard</td><td>11</td></tr>\n",
       "<tr><td>Michael Davis</td><td>Standard</td><td>11</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------+---------+-------------+\n",
       "| customer_name|room_type|total_entries|\n",
       "+--------------+---------+-------------+\n",
       "|   James Smith|Executive|           10|\n",
       "|Robert Johnson|   Deluxe|           10|\n",
       "|   William Lee| Standard|           11|\n",
       "| Michael Davis| Standard|           11|\n",
       "+--------------+---------+-------------+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"select customer_name, room_type, \n",
    "count(*) as total_entries from hoteldata \n",
    "group by customer_name, room_type\n",
    "having count(customer_name) >= 10\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f415840",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>We can conclude that there are only 4 customers out of 22 distinct who have stayed 10 or more times in different rooms making them frequent customers.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8047ecd0",
   "metadata": {},
   "source": [
    "### The above data only had 106 records in total so I will be using a different dataset (with more records) to perform Advanced Grouping and Windowing aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d236d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a new spark session\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "spark = SparkSession. \\\n",
    "builder. \\\n",
    "config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "enableHiveSupport(). \\\n",
    "master(\"yarn\"). \\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0795e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+-----------+-------------+------------+\n",
      "|country       |weeknum|numinvoices|totalquantity|invoicevalue|\n",
      "+--------------+-------+-----------+-------------+------------+\n",
      "|Spain         |49     |1          |67           |174.72      |\n",
      "|Germany       |48     |11         |1795         |1600.0      |\n",
      "|Lithuania     |48     |3          |622          |1598.06     |\n",
      "|Germany       |49     |12         |1852         |1800.0      |\n",
      "|Bahrain       |51     |1          |54           |205.74      |\n",
      "|Iceland       |49     |1          |319          |711.79      |\n",
      "|India         |51     |5          |95           |300.0       |\n",
      "|Australia     |50     |2          |133          |387.95      |\n",
      "|Italy         |49     |1          |-2           |-17.0       |\n",
      "|India         |49     |5          |1280         |3284.1      |\n",
      "|Spain         |50     |2          |400          |1049.01     |\n",
      "|United Kingdom|51     |200        |28782        |75103.46    |\n",
      "|Norway        |49     |1          |1730         |1867.98     |\n",
      "|United Kingdom|48     |478        |68865        |166116.72   |\n",
      "|France        |51     |5          |847          |500.0       |\n",
      "|Portugal      |49     |4          |726          |1844.67     |\n",
      "|Spain         |48     |1          |400          |620.0       |\n",
      "|India         |48     |7          |2822         |300.0       |\n",
      "|Germany       |50     |15         |1973         |1800.0      |\n",
      "|Italy         |51     |1          |131          |383.7       |\n",
      "+--------------+-------+-----------+-------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the Window data modified for this analysis.\n",
    "windows_schema = \"country string, weeknum long, numinvoices long, totalquantity long, invoicevalue float\"\n",
    "\n",
    "window_data = spark.read.format(\"csv\").option(\"header\", \"true\").schema(windows_schema).load(\"/public/trendytech/datasets/windowdatamodified.csv\")\n",
    "\n",
    "# Print the first 20 rows to see the data format\n",
    "window_data.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4131ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- weeknum: long (nullable = true)\n",
      " |-- numinvoices: long (nullable = true)\n",
      " |-- totalquantity: long (nullable = true)\n",
      " |-- invoicevalue: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the dataframe schema to ensure all columns are of correct data types as intended\n",
    "\n",
    "window_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c5caa9",
   "metadata": {},
   "source": [
    "**Now let's deep dive to perform some windowing aggregations:**\n",
    "\n",
    "`Note: I will follow the Spark SQL style in this notebook to perform different aggregations. We will cover the below scenarios as part of windowing aggregations:`\n",
    "\n",
    "* Use Rank() function\n",
    "* Use denserank() function\n",
    "* Use row_number() function\n",
    "* Use lag and lead functions.\n",
    "* Run a pivot table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48d6f84",
   "metadata": {},
   "source": [
    "`As we know that, in order to perform all above windowing functions, we need to define a window which should contain a:`\n",
    "\n",
    "* Partitioning Column\n",
    "* Sorting Column\n",
    "* Size of Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dc8e9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+-------------+------------+------------------+\n",
      "|country|weeknum|numinvoices|totalquantity|invoicevalue|     running_total|\n",
      "+-------+-------+-----------+-------------+------------+------------------+\n",
      "| Sweden|     50|          3|         3714|      2646.3| 2646.300048828125|\n",
      "|Germany|     48|         11|         1795|      1600.0|            1600.0|\n",
      "|Germany|     49|         12|         1852|      1800.0|            3400.0|\n",
      "|Germany|     50|         15|         1973|      1800.0|            5200.0|\n",
      "|Germany|     51|          5|         1103|      1600.0|            6800.0|\n",
      "| France|     48|          4|         1299|       500.0|             500.0|\n",
      "| France|     49|          9|         2303|       500.0|            1000.0|\n",
      "| France|     50|          6|          529|      537.32|1537.3200073242188|\n",
      "| France|     51|          5|          847|       500.0|2037.3200073242188|\n",
      "|Belgium|     48|          1|          528|       800.0|             800.0|\n",
      "|Belgium|     50|          2|          285|      625.16|1425.1599731445312|\n",
      "|Belgium|     51|          2|          942|       800.0|2225.1599731445312|\n",
      "|Finland|     50|          1|         1254|       892.8| 892.7999877929688|\n",
      "|  India|     48|          7|         2822|       300.0|             300.0|\n",
      "|  India|     49|          5|         1280|      3284.1|  3584.10009765625|\n",
      "|  India|     50|          5|         1184|     2321.78| 5905.880126953125|\n",
      "|  India|     51|          5|           95|       300.0| 6205.880126953125|\n",
      "|  Italy|     48|          1|          164|       427.8|427.79998779296875|\n",
      "|  Italy|     49|          1|           -2|       -17.0|410.79998779296875|\n",
      "|  Italy|     51|          1|          131|       383.7|             794.5|\n",
      "+-------+-------+-----------+-------------+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's define the window based on the data we have read\n",
    "\n",
    "mywindow_1 = Window.partitionBy(\"country\").orderBy(\"weeknum\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "# Calculating the running cost after partitioning by Country and sorting by Week number\n",
    "windows_df_1 = window_data.withColumn(\"running_total\", sum(\"invoicevalue\").over(mywindow_1))\n",
    "windows_df_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9b1a57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+-------------+------------+------------------+----+\n",
      "|country|weeknum|numinvoices|totalquantity|invoicevalue|     running_total|rank|\n",
      "+-------+-------+-----------+-------------+------------+------------------+----+\n",
      "| Sweden|     50|          3|         3714|      2646.3| 2646.300048828125|   1|\n",
      "|Germany|     48|         11|         1795|      1600.0|            1600.0|   1|\n",
      "|Germany|     49|         12|         1852|      1800.0|            3400.0|   2|\n",
      "|Germany|     50|         15|         1973|      1800.0|            5200.0|   3|\n",
      "|Germany|     51|          5|         1103|      1600.0|            6800.0|   4|\n",
      "| France|     48|          4|         1299|       500.0|             500.0|   1|\n",
      "| France|     49|          9|         2303|       500.0|            1000.0|   2|\n",
      "| France|     50|          6|          529|      537.32|1537.3200073242188|   3|\n",
      "| France|     51|          5|          847|       500.0|2037.3200073242188|   4|\n",
      "|Belgium|     48|          1|          528|       800.0|             800.0|   1|\n",
      "|Belgium|     50|          2|          285|      625.16|1425.1599731445312|   2|\n",
      "|Belgium|     51|          2|          942|       800.0|2225.1599731445312|   3|\n",
      "|Finland|     50|          1|         1254|       892.8| 892.7999877929688|   1|\n",
      "|  India|     48|          7|         2822|       300.0|             300.0|   1|\n",
      "|  India|     49|          5|         1280|      3284.1|  3584.10009765625|   2|\n",
      "|  India|     50|          5|         1184|     2321.78| 5905.880126953125|   3|\n",
      "|  India|     51|          5|           95|       300.0| 6205.880126953125|   4|\n",
      "|  Italy|     48|          1|          164|       427.8|427.79998779296875|   1|\n",
      "|  Italy|     49|          1|           -2|       -17.0|410.79998779296875|   2|\n",
      "|  Italy|     51|          1|          131|       383.7|             794.5|   3|\n",
      "+-------+-------+-----------+-------------+------------+------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windows_df_rank_1 = windows_df_1.withColumn(\"rank\", rank().over(mywindow_1))\n",
    "windows_df_rank_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26f86e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+-------------+------------+------------------+----+\n",
      "|country|weeknum|numinvoices|totalquantity|invoicevalue|     running_total|rank|\n",
      "+-------+-------+-----------+-------------+------------+------------------+----+\n",
      "| Sweden|     50|          3|         3714|      2646.3| 2646.300048828125|   1|\n",
      "|Germany|     48|         11|         1795|      1600.0|            1600.0|   1|\n",
      "|Germany|     49|         12|         1852|      1800.0|            3400.0|   2|\n",
      "|Germany|     50|         15|         1973|      1800.0|            5200.0|   3|\n",
      "|Germany|     51|          5|         1103|      1600.0|            6800.0|   4|\n",
      "| France|     48|          4|         1299|       500.0|             500.0|   1|\n",
      "| France|     49|          9|         2303|       500.0|            1000.0|   2|\n",
      "| France|     50|          6|          529|      537.32|1537.3200073242188|   3|\n",
      "| France|     51|          5|          847|       500.0|2037.3200073242188|   4|\n",
      "|Belgium|     48|          1|          528|       800.0|             800.0|   1|\n",
      "|Belgium|     50|          2|          285|      625.16|1425.1599731445312|   2|\n",
      "|Belgium|     51|          2|          942|       800.0|2225.1599731445312|   3|\n",
      "|Finland|     50|          1|         1254|       892.8| 892.7999877929688|   1|\n",
      "|  India|     48|          7|         2822|       300.0|             300.0|   1|\n",
      "|  India|     49|          5|         1280|      3284.1|  3584.10009765625|   2|\n",
      "|  India|     50|          5|         1184|     2321.78| 5905.880126953125|   3|\n",
      "|  India|     51|          5|           95|       300.0| 6205.880126953125|   4|\n",
      "|  Italy|     48|          1|          164|       427.8|427.79998779296875|   1|\n",
      "|  Italy|     49|          1|           -2|       -17.0|410.79998779296875|   2|\n",
      "|  Italy|     51|          1|          131|       383.7|             794.5|   3|\n",
      "+-------+-------+-----------+-------------+------------+------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windows_df_denserank_1 = windows_df_1.withColumn(\"rank\", dense_rank().over(mywindow_1))\n",
    "windows_df_denserank_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7a092cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+-------------+------------+------------------+----+\n",
      "|country|weeknum|numinvoices|totalquantity|invoicevalue|     running_total|rank|\n",
      "+-------+-------+-----------+-------------+------------+------------------+----+\n",
      "| Sweden|     50|          3|         3714|      2646.3| 2646.300048828125|   1|\n",
      "|Germany|     48|         11|         1795|      1600.0|            1600.0|   1|\n",
      "|Germany|     49|         12|         1852|      1800.0|            3400.0|   2|\n",
      "|Germany|     50|         15|         1973|      1800.0|            5200.0|   3|\n",
      "|Germany|     51|          5|         1103|      1600.0|            6800.0|   4|\n",
      "| France|     48|          4|         1299|       500.0|             500.0|   1|\n",
      "| France|     49|          9|         2303|       500.0|            1000.0|   2|\n",
      "| France|     50|          6|          529|      537.32|1537.3200073242188|   3|\n",
      "| France|     51|          5|          847|       500.0|2037.3200073242188|   4|\n",
      "|Belgium|     48|          1|          528|       800.0|             800.0|   1|\n",
      "|Belgium|     50|          2|          285|      625.16|1425.1599731445312|   2|\n",
      "|Belgium|     51|          2|          942|       800.0|2225.1599731445312|   3|\n",
      "|Finland|     50|          1|         1254|       892.8| 892.7999877929688|   1|\n",
      "|  India|     48|          7|         2822|       300.0|             300.0|   1|\n",
      "|  India|     49|          5|         1280|      3284.1|  3584.10009765625|   2|\n",
      "|  India|     50|          5|         1184|     2321.78| 5905.880126953125|   3|\n",
      "|  India|     51|          5|           95|       300.0| 6205.880126953125|   4|\n",
      "|  Italy|     48|          1|          164|       427.8|427.79998779296875|   1|\n",
      "|  Italy|     49|          1|           -2|       -17.0|410.79998779296875|   2|\n",
      "|  Italy|     51|          1|          131|       383.7|             794.5|   3|\n",
      "+-------+-------+-----------+-------------+------------+------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windows_df_row_num_1 = windows_df_1.withColumn(\"rank\", row_number().over(mywindow_1))\n",
    "windows_df_row_num_1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ab4be8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>When we used partitionBy column as 'country' and orderBy column as 'weeknum', we can conclude see that there is no difference at all in the outputs of rank, denserank and row_num functions because there are no repetiting weeks for any country.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fed3db4",
   "metadata": {},
   "source": [
    "`Now, let's try to use the orderBy column as 'invoicevalue and see what difference does it make in the output of all the 3 functions'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63a5c9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+-------------+------------+------------------+\n",
      "|country|weeknum|numinvoices|totalquantity|invoicevalue|     running_total|\n",
      "+-------+-------+-----------+-------------+------------+------------------+\n",
      "| Sweden|     50|          3|         3714|      2646.3| 2646.300048828125|\n",
      "|Germany|     48|         11|         1795|      1600.0|            1600.0|\n",
      "|Germany|     51|          5|         1103|      1600.0|            3200.0|\n",
      "|Germany|     49|         12|         1852|      1800.0|            5000.0|\n",
      "|Germany|     50|         15|         1973|      1800.0|            6800.0|\n",
      "| France|     51|          5|          847|       500.0|             500.0|\n",
      "| France|     49|          9|         2303|       500.0|            1000.0|\n",
      "| France|     48|          4|         1299|       500.0|            1500.0|\n",
      "| France|     50|          6|          529|      537.32|2037.3200073242188|\n",
      "|Belgium|     50|          2|          285|      625.16| 625.1599731445312|\n",
      "|Belgium|     48|          1|          528|       800.0|1425.1599731445312|\n",
      "|Belgium|     51|          2|          942|       800.0|2225.1599731445312|\n",
      "|Finland|     50|          1|         1254|       892.8| 892.7999877929688|\n",
      "|  India|     51|          5|           95|       300.0|             300.0|\n",
      "|  India|     48|          7|         2822|       300.0|             600.0|\n",
      "|  India|     50|          5|         1184|     2321.78| 2921.780029296875|\n",
      "|  India|     49|          5|         1280|      3284.1| 6205.880126953125|\n",
      "|  Italy|     49|          1|           -2|       -17.0|             -17.0|\n",
      "|  Italy|     51|          1|          131|       383.7|366.70001220703125|\n",
      "|  Italy|     48|          1|          164|       427.8|             794.5|\n",
      "+-------+-------+-----------+-------------+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's define the window based on the data we have read\n",
    "\n",
    "mywindow_2 = Window.partitionBy(\"country\").orderBy(\"invoicevalue\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "# Calculating the running cost after partitioning by Country and sorting by Week number\n",
    "windows_df_2 = window_data.withColumn(\"running_total\", sum(\"invoicevalue\").over(mywindow_2))\n",
    "windows_df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e8f893b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+-------------+------------+------------------+----+\n",
      "|country|weeknum|numinvoices|totalquantity|invoicevalue|     running_total|rank|\n",
      "+-------+-------+-----------+-------------+------------+------------------+----+\n",
      "| Sweden|     50|          3|         3714|      2646.3| 2646.300048828125|   1|\n",
      "|Germany|     48|         11|         1795|      1600.0|            1600.0|   1|\n",
      "|Germany|     51|          5|         1103|      1600.0|            3200.0|   1|\n",
      "|Germany|     49|         12|         1852|      1800.0|            5000.0|   3|\n",
      "|Germany|     50|         15|         1973|      1800.0|            6800.0|   3|\n",
      "| France|     51|          5|          847|       500.0|             500.0|   1|\n",
      "| France|     49|          9|         2303|       500.0|            1000.0|   1|\n",
      "| France|     48|          4|         1299|       500.0|            1500.0|   1|\n",
      "| France|     50|          6|          529|      537.32|2037.3200073242188|   4|\n",
      "|Belgium|     50|          2|          285|      625.16| 625.1599731445312|   1|\n",
      "|Belgium|     48|          1|          528|       800.0|1425.1599731445312|   2|\n",
      "|Belgium|     51|          2|          942|       800.0|2225.1599731445312|   2|\n",
      "|Finland|     50|          1|         1254|       892.8| 892.7999877929688|   1|\n",
      "|  India|     51|          5|           95|       300.0|             300.0|   1|\n",
      "|  India|     48|          7|         2822|       300.0|             600.0|   1|\n",
      "|  India|     50|          5|         1184|     2321.78| 2921.780029296875|   3|\n",
      "|  India|     49|          5|         1280|      3284.1| 6205.880126953125|   4|\n",
      "|  Italy|     49|          1|           -2|       -17.0|             -17.0|   1|\n",
      "|  Italy|     51|          1|          131|       383.7|366.70001220703125|   2|\n",
      "|  Italy|     48|          1|          164|       427.8|             794.5|   3|\n",
      "+-------+-------+-----------+-------------+------------+------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windows_df_rank_2 = windows_df_2.withColumn(\"rank\", rank().over(mywindow_2))\n",
    "windows_df_rank_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7684a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+-------------+------------+------------------+----+\n",
      "|country|weeknum|numinvoices|totalquantity|invoicevalue|     running_total|rank|\n",
      "+-------+-------+-----------+-------------+------------+------------------+----+\n",
      "| Sweden|     50|          3|         3714|      2646.3| 2646.300048828125|   1|\n",
      "|Germany|     48|         11|         1795|      1600.0|            1600.0|   1|\n",
      "|Germany|     51|          5|         1103|      1600.0|            3200.0|   1|\n",
      "|Germany|     49|         12|         1852|      1800.0|            5000.0|   2|\n",
      "|Germany|     50|         15|         1973|      1800.0|            6800.0|   2|\n",
      "| France|     51|          5|          847|       500.0|             500.0|   1|\n",
      "| France|     49|          9|         2303|       500.0|            1000.0|   1|\n",
      "| France|     48|          4|         1299|       500.0|            1500.0|   1|\n",
      "| France|     50|          6|          529|      537.32|2037.3200073242188|   2|\n",
      "|Belgium|     50|          2|          285|      625.16| 625.1599731445312|   1|\n",
      "|Belgium|     48|          1|          528|       800.0|1425.1599731445312|   2|\n",
      "|Belgium|     51|          2|          942|       800.0|2225.1599731445312|   2|\n",
      "|Finland|     50|          1|         1254|       892.8| 892.7999877929688|   1|\n",
      "|  India|     51|          5|           95|       300.0|             300.0|   1|\n",
      "|  India|     48|          7|         2822|       300.0|             600.0|   1|\n",
      "|  India|     50|          5|         1184|     2321.78| 2921.780029296875|   2|\n",
      "|  India|     49|          5|         1280|      3284.1| 6205.880126953125|   3|\n",
      "|  Italy|     49|          1|           -2|       -17.0|             -17.0|   1|\n",
      "|  Italy|     51|          1|          131|       383.7|366.70001220703125|   2|\n",
      "|  Italy|     48|          1|          164|       427.8|             794.5|   3|\n",
      "+-------+-------+-----------+-------------+------------+------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windows_df_denserank_2 = windows_df_2.withColumn(\"rank\", dense_rank().over(mywindow_2))\n",
    "windows_df_denserank_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3aa6fac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+-------------+------------+------------------+----+\n",
      "|country|weeknum|numinvoices|totalquantity|invoicevalue|     running_total|rank|\n",
      "+-------+-------+-----------+-------------+------------+------------------+----+\n",
      "| Sweden|     50|          3|         3714|      2646.3| 2646.300048828125|   1|\n",
      "|Germany|     48|         11|         1795|      1600.0|            1600.0|   1|\n",
      "|Germany|     51|          5|         1103|      1600.0|            3200.0|   2|\n",
      "|Germany|     49|         12|         1852|      1800.0|            5000.0|   3|\n",
      "|Germany|     50|         15|         1973|      1800.0|            6800.0|   4|\n",
      "| France|     51|          5|          847|       500.0|             500.0|   1|\n",
      "| France|     49|          9|         2303|       500.0|            1000.0|   2|\n",
      "| France|     48|          4|         1299|       500.0|            1500.0|   3|\n",
      "| France|     50|          6|          529|      537.32|2037.3200073242188|   4|\n",
      "|Belgium|     50|          2|          285|      625.16| 625.1599731445312|   1|\n",
      "|Belgium|     48|          1|          528|       800.0|1425.1599731445312|   2|\n",
      "|Belgium|     51|          2|          942|       800.0|2225.1599731445312|   3|\n",
      "|Finland|     50|          1|         1254|       892.8| 892.7999877929688|   1|\n",
      "|  India|     51|          5|           95|       300.0|             300.0|   1|\n",
      "|  India|     48|          7|         2822|       300.0|             600.0|   2|\n",
      "|  India|     50|          5|         1184|     2321.78| 2921.780029296875|   3|\n",
      "|  India|     49|          5|         1280|      3284.1| 6205.880126953125|   4|\n",
      "|  Italy|     49|          1|           -2|       -17.0|             -17.0|   1|\n",
      "|  Italy|     51|          1|          131|       383.7|366.70001220703125|   2|\n",
      "|  Italy|     48|          1|          164|       427.8|             794.5|   3|\n",
      "+-------+-------+-----------+-------------+------------+------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windows_df_row_num_3 = windows_df_2.withColumn(\"rank\", row_number().over(mywindow_2))\n",
    "windows_df_row_num_3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fb11ae",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>As we can see that when we used partitionBy column as 'country' and orderBy column as 'invoicevalue', we can notice a clear difference in the outputs of rank() and denserank() functions becaause we have duplicate values in invoice value column for differently grouped countries.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ef1a17",
   "metadata": {},
   "source": [
    "`Now, let's try to use lag and lead functions'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "929b9dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mywindow_lag = Window.partitionBy(\"country\").orderBy(\"weeknum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "367d80cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+-------------+------------+------------------+-------------+\n",
      "|country|weeknum|numinvoices|totalquantity|invoicevalue|     running_total|previous_week|\n",
      "+-------+-------+-----------+-------------+------------+------------------+-------------+\n",
      "| Sweden|     50|          3|         3714|      2646.3| 2646.300048828125|         null|\n",
      "|Germany|     48|         11|         1795|      1600.0|            1600.0|         null|\n",
      "|Germany|     49|         12|         1852|      1800.0|            3400.0|       1600.0|\n",
      "|Germany|     50|         15|         1973|      1800.0|            5200.0|       1800.0|\n",
      "|Germany|     51|          5|         1103|      1600.0|            6800.0|       1800.0|\n",
      "| France|     48|          4|         1299|       500.0|             500.0|         null|\n",
      "| France|     49|          9|         2303|       500.0|            1000.0|        500.0|\n",
      "| France|     50|          6|          529|      537.32|1537.3200073242188|        500.0|\n",
      "| France|     51|          5|          847|       500.0|2037.3200073242188|       537.32|\n",
      "|Belgium|     48|          1|          528|       800.0|             800.0|         null|\n",
      "|Belgium|     50|          2|          285|      625.16|1425.1599731445312|        800.0|\n",
      "|Belgium|     51|          2|          942|       800.0|2225.1599731445312|       625.16|\n",
      "|Finland|     50|          1|         1254|       892.8| 892.7999877929688|         null|\n",
      "|  India|     48|          7|         2822|       300.0|             300.0|         null|\n",
      "|  India|     49|          5|         1280|      3284.1|  3584.10009765625|        300.0|\n",
      "|  India|     50|          5|         1184|     2321.78| 5905.880126953125|       3284.1|\n",
      "|  India|     51|          5|           95|       300.0| 6205.880126953125|      2321.78|\n",
      "|  Italy|     48|          1|          164|       427.8|427.79998779296875|         null|\n",
      "|  Italy|     49|          1|           -2|       -17.0|410.79998779296875|        427.8|\n",
      "|  Italy|     51|          1|          131|       383.7|             794.5|        -17.0|\n",
      "+-------+-------+-----------+-------------+------------+------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windows_df_lag_1 = windows_df_1.withColumn(\"previous_week\", lag(\"invoicevalue\").over(mywindow_lag))\n",
    "\n",
    "windows_df_lag_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1c55e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mywindow_lead = Window.partitionBy(\"country\").orderBy(\"weeknum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27c239f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+-------------+------------+------------------+---------+\n",
      "|country|weeknum|numinvoices|totalquantity|invoicevalue|     running_total|next_week|\n",
      "+-------+-------+-----------+-------------+------------+------------------+---------+\n",
      "| Sweden|     50|          3|         3714|      2646.3| 2646.300048828125|     null|\n",
      "|Germany|     48|         11|         1795|      1600.0|            1600.0|   1800.0|\n",
      "|Germany|     49|         12|         1852|      1800.0|            3400.0|   1800.0|\n",
      "|Germany|     50|         15|         1973|      1800.0|            5200.0|   1600.0|\n",
      "|Germany|     51|          5|         1103|      1600.0|            6800.0|     null|\n",
      "| France|     48|          4|         1299|       500.0|             500.0|    500.0|\n",
      "| France|     49|          9|         2303|       500.0|            1000.0|   537.32|\n",
      "| France|     50|          6|          529|      537.32|1537.3200073242188|    500.0|\n",
      "| France|     51|          5|          847|       500.0|2037.3200073242188|     null|\n",
      "|Belgium|     48|          1|          528|       800.0|             800.0|   625.16|\n",
      "|Belgium|     50|          2|          285|      625.16|1425.1599731445312|    800.0|\n",
      "|Belgium|     51|          2|          942|       800.0|2225.1599731445312|     null|\n",
      "|Finland|     50|          1|         1254|       892.8| 892.7999877929688|     null|\n",
      "|  India|     48|          7|         2822|       300.0|             300.0|   3284.1|\n",
      "|  India|     49|          5|         1280|      3284.1|  3584.10009765625|  2321.78|\n",
      "|  India|     50|          5|         1184|     2321.78| 5905.880126953125|    300.0|\n",
      "|  India|     51|          5|           95|       300.0| 6205.880126953125|     null|\n",
      "|  Italy|     48|          1|          164|       427.8|427.79998779296875|    -17.0|\n",
      "|  Italy|     49|          1|           -2|       -17.0|410.79998779296875|    383.7|\n",
      "|  Italy|     51|          1|          131|       383.7|             794.5|     null|\n",
      "+-------+-------+-----------+-------------+------------+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windows_df_lead_1 = windows_df_1.withColumn(\"next_week\", lead(\"invoicevalue\").over(mywindow_lead))\n",
    "\n",
    "windows_df_lead_1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2c5886",
   "metadata": {},
   "source": [
    "### Dealing with NULLS in Apache Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fb15458",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    ('Alice', 25, 'New York'),\n",
    "     ('Bob', 25, 'Los Angeles'),\n",
    "    ('Charlie', None, 'Chicago'),\n",
    "    (None, 33, 'Houston'),\n",
    "    ('Frank', 27, None),\n",
    "    ('Henry', 30, 'Seattle'),\n",
    "    (None, None, None),\n",
    "    ('Ivy', None, 'Denver')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec6bfa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampledata_schema = \"student_name string, student_age int, city string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8aca8626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+-----------+\n",
      "|student_name|student_age|       city|\n",
      "+------------+-----------+-----------+\n",
      "|       Alice|         25|   New York|\n",
      "|         Bob|         25|Los Angeles|\n",
      "|     Charlie|       null|    Chicago|\n",
      "|        null|         33|    Houston|\n",
      "|       Frank|         27|       null|\n",
      "|       Henry|         30|    Seattle|\n",
      "|        null|       null|       null|\n",
      "|         Ivy|       null|     Denver|\n",
      "+------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampledata_df = spark.createDataFrame(data=data, schema=sampledata_schema)\n",
    "sampledata_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70489b76",
   "metadata": {},
   "source": [
    "`We can drop the nulls by dropping the rows having NA's`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7c04f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+-----------+\n",
      "|student_name|student_age|       city|\n",
      "+------------+-----------+-----------+\n",
      "|       Alice|         25|   New York|\n",
      "|         Bob|         25|Los Angeles|\n",
      "|       Henry|         30|    Seattle|\n",
      "+------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "refined_df = sampledata_df.dropna()\n",
    "refined_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d70d9c",
   "metadata": {},
   "source": [
    "`We can also drop Nulls based on specific columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0289a615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+-----------+\n",
      "|student_name|student_age|       city|\n",
      "+------------+-----------+-----------+\n",
      "|       Alice|         25|   New York|\n",
      "|         Bob|         25|Los Angeles|\n",
      "|       Frank|         27|       null|\n",
      "|       Henry|         30|    Seattle|\n",
      "+------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "refined_df_columns = sampledata_df.dropna(subset=['student_name', 'student_age'])\n",
    "refined_df_columns.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8801931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
